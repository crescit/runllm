# Prompt

Mac M1 Optimized LLMs to run through Github Actions

- [Llama.cpp](https://github.com/ggerganov/llama.cpp)
- [CRD716/ggml-vicuna-1.1-quantized](https://huggingface.co/CRD716/ggml-vicuna-1.1-quantized)

# Usage

## Setup

```
git clone https://github.com/opszero/prompt && cd prompt && ./build.sh
```

# Example

```
cd example && ./example.sh
```

# Pro Support

<a href="https://www.opszero.com"><img src="https://media.opszero.com/insights/brands/logo/2023/04/26/02/04/12/opsZero_logo.svg" width="300px"/></a>

[opsZero provides support](https://www.opszero.com) for our modules including:

- Slack & Email support
- One on One Video Calls
- Implementation Guidance
